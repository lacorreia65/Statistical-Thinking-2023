---
title: "Statistical Rethinking 2023"
author: "Luis Correia"
format: html
editor: visual
---

## Lecture 1

The content of this lecture should be reviewed and posted.

{{< pagebreak >}}

## Lecture 2

\<To be reviewed with lecture contents\>

A new model is born when we write:

$$
W\sim Binomial(N,p)
$$

with

$$
p\sim Unif(0,1)
$$

Simulation of Bayesian Experiment

```{r}
# definegrid
p_grid <-seq(from=0,to=1,length.out=20)

# defineprior
#prior <-rep(1,20)
prior <-ifelse(p_grid<0.5,0,1)

# computelikelihoodateachvalueingrid
likelihood <-dbinom(6,size=9,prob=p_grid)

# computeproductoflikelihoodandprior
unstd.posterior <-likelihood*prior

# standardizetheposterior,soitsumsto1
posterior <-unstd.posterior/sum(unstd.posterior)
```

```{r}
plot( p_grid,posterior,type="b",
xlab="probability ofwater",ylab="posteriorprobability")
mtext( "20points")
```

### Homework 1

Suppose the globe tossing data had turned into a 4-water and 11-land. Construct the posterior distribution.

```{r}
# 2.7 analyticalcalculation
W <-6
L <-3
curve( dbeta(x,W+1,L+1),from=0,to=1)

# quadraticapproximation
curve( dnorm(x,0.67,0.16),lty=2,add=TRUE)
```

Simulation of Bayesian Experiment

```{r}
# definegrid
p_grid <-seq(from=0,to=1,length.out=20)

# defineprior
#prior <-rep(1,20)
prior <-ifelse(p_grid<0.5,0,1)

# computelikelihoodateachvalueingrid
likelihood <-dbinom(6,size=9,prob=p_grid)

# computeproductoflikelihoodandprior
unstd.posterior <-likelihood*prior

# standardizetheposterior,soitsumsto1
posterior <-unstd.posterior/sum(unstd.posterior)
```

```{r}
plot( p_grid,posterior,type="b",
xlab="probability ofwater",ylab="posteriorprobability")
mtext( "20points")
```

### Homework 1

Suppose the globe tossing data had turned into a 4-water and 11-land. Construct the posterior distribution.

```{r}
# 2.7 analyticalcalculation
W <-6
L <-3
curve( dbeta(x,W+1,L+1),from=0,to=1)

# quadraticapproximation
curve( dnorm(x,0.67,0.16),lty=2,add=TRUE)
```

```{r}
p <- c(0, .25, .5, .75, 1)
model <- sapply(p, function (p, W, L) return (4*p)^W*(4-4*p)^L)
print(model)
```

```{r}
n_samples <-1000
p <-rep(NA,n_samples)
p[1] <-0.5
W <-6
L <-3
for (i in 2:n_samples){
  p_new <-rnorm(1,p[i-1],0.1)
  if (p_new < 0) p_new <- abs(p_new)
  if (p_new > 1) p_new <- 2-p_new
  q0 <-dbinom(W,W+L,p[i-1])
  q1 <-dbinom(W,W+L,p_new)
  p[i] <-ifelse(runif(1)<q1/q0,p_new,p[i-1])
}
```

```{r}
plot(density(p),xlim=c(0,1))
curve( dbeta(x, W+1, L+1 ),lty=2,add=TRUE)
```

```{r}
sample <- c('W','L','W','W','W','L','W','L','W')
W <- sum(sample=='W') # No. of W observed
L <- sum(sample=='L') # No. of L observed
p <- c(0,.25,.5,.75,1) # Proportions W
ways <- sapply(p, function (q) (q*4)^W*((1-q)*4)^L)
prob <- ways/sum(ways)
cbind(p, ways, prob)
```

```{r}
sim_globe <- function (p=.7, N = 9) {
  sample(c('W','L'), size = N, prob = c(p, 1-p), replace=TRUE)
}
sim_globe()
```

```{r}
replicate(sim_globe(p = .5, N = 9), n = 10)
```

```{r}
sum(sim_globe(p = .5, N = 1e4 )=='W')/1e4
```

```{r}
library(ggplot2)

compute_posterior <- function (the_sample, poss = c(0,.25,.5,.75,1)) {
  W <- sum(the_sample=='W')  # No. of 'W'
  L <- sum(the_sample=='L')  # No. of 'L'
  ways <- sapply(p, function (q) (q*4)^W*((1-q)*4)^L)
  post <- ways/sum(ways)
  # bars <- sapply(post, function (q) make_bar(q))
  # data.frame(poss, ways, post=round(post,3), bars)
  df <- data.frame(poss, ways, post=round(post,3))
  ggplot(aes(x=poss, y=post), data=df)+
    geom_bar(stat="identity")
}
```

```{r}
the_sample <- sim_globe()

print(the_sample)

compute_posterior(the_sample)
```

Calculating the posteriors using the conjugate prior beta

```{r}
library(rethinking)
post_samples <- rbeta(1e3, 6+1, 3+1)
```

```{r}
dens(post_samples, lwd=4, col=2, xlab="proportion water", adj=.1)
curve(dbeta(x, 6+1, 3+1), add=TRUE, lty=2, lwd=3)
```

```{r}
w <-6;n<-9;
p_grid <-seq(from=0,to=1,length.out=100)
posterior <-dbinom(w,n,p_grid)*dunif(p_grid,0,1)
posterior <-posterior/sum(posterior)
plot(posterior,col=2, type="l")
```

## Lecture 3

### Workflow

> 1.  State a clear Question
> 2.  State your causal Assumptions
> 3.  Use the causal sketch to define the Generative Model
> 4.  Use the Generative Model to build an Estimator
> 5.  Profit

Using the Howell database, we will construct a model to analyse the causal relationship between Height and Weight.

A new model is born when we write:

$$
W = \beta H + U
$$

```{r}
library(rethinking)

sim_weight <- function (H, b, sd) {
  U <-  rnorm(length(H),0,sd)
  W <- b*H + U
  return(W)
}
```

```{r}
H <-  runif(200, min=130, max=170)
W <- sim_weight(H, b=.5, sd=5)
plot(W ~ H, col=2, lwd=3)
```

Our model can be written as follows

$$
W_i=\beta H_i+U_i
$$

$$
H_i\sim Uniform(130, 170)
$$

$$
U_i\sim Normal(0,\sigma^2)
$$

and our estimator can then be written as

$$
E(W_i|H_i)=\alpha+\beta H_i
$$

The posterior distribution is now written as\
$$
Pr(\alpha,\beta,\sigma^2|H_i,W_i)\propto Pr(W_i|H_i,\alpha,\beta,\sigma^2)Pr(\alpha,\beta,\sigma^2)
$$

Now our Bayesian Model is defined as follows:

$$
W_i\sim Normal(\mu_i,\sigma^2)
$$

$$
\mu_i = \alpha+\beta H_i
$$

```{r}
library(rethinking)

data(Howell1)
d <-Howell1[Howell1$age>=18,]
```

```{r}
#Similate a sample of 10 people
set.seed(93)
H <- runif(10,130,170)
W <- sim_weight(H,b=0.5, sd=5)

#Run Model
m3.1 <- quap(
  alist(
    W ~ dnorm(mu,sigma),
    mu <- a + b*H,
    a ~ dnorm(0,10),
    b ~ dunif(0,1),
    sigma~dunif(0,10)
),data=list(W=W, H=H))

#Summary
precis(m3.1)
```

```{r}
n <- 1e3
a <- rnorm(n,0,10)
b <- runif(n,0,1)
plot(NULL,xlim=c(130,170),ylim=c(50,90),
     xlab="height(cm)", ylab="weight(kg)",)
for (j in 1:50 ) abline(a=a[j], b=b[j], lwd=2, col=2)
```

```{r}
dat <- list(W=d$weight, H=d$height)
#k <- 10
#dat <- list(W=d$weight[1:k], H=d$height[1:k])

#Run Model
m3.2 <- quap(
  alist(
    W ~ dnorm(mu,sigma),
    mu <- a + b*H,
    a ~ dnorm(0,10),
    b ~ dunif(0,1),
    sigma~dunif(0,10)
),data=dat)
precis(m3.2)
post <- extract.samples(m3.2)
plot(dat$H,dat$W,col=2,lwd=3,
     xlim=c(min(dat$H),max(dat$H)), ylim=c(min(30,dat$w),max(dat$W)),
     xlab="height(cm)", ylab="weight(kg)")
for (j in 1:20)
  abline(a=post$a[j],b=post$b[j], lty=1)
```

```{r}
post <- extract.samples(m3.2)
pairs(post)
head(post)
plot(d$height,d$weight,col=2,lwd=3,
     xlab="height(cm)", ylab="weight(kg)")
for (j in 1:20)
  abline(a=post$a[j],b=post$b[j], lty=1)

height_seq <- seq(130,190,len=20)
W_postpred <- sim(m3.2,data=list(H=height_seq))
W_PI <- apply(W_postpred,2,PI)
lines(height_seq,W_PI[1,],lty=2,lwd=2)
lines(height_seq,W_PI[2,],lty=2,lwd=2)
```
